{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UyFuMGdKwSN6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import pathlib\n",
        "\n",
        "from torch import optim\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input,Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from keras import optimizers, initializers, regularizers, metrics\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xxppmJtBxVoU"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oO08mjOtZcYm"
      },
      "outputs": [],
      "source": [
        "# !unzip -qq \"/content/drive/MyDrive/cars.zip\" -d \"/content/drive/MyDrive/cars\"\n",
        "# !unzip -qq \"/content/drive/MyDrive/boongboong.zip\" -d \"/content/drive/MyDrive/boongboong\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS-q4Z5sZpAb",
        "outputId": "0a9c6750-dd72-40f7-dbff-0768c2d90742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9900 files belonging to 33 classes.\n",
            "Using 7920 files for training.\n",
            "Found 9900 files belonging to 33 classes.\n",
            "Using 1980 files for validation.\n",
            "Epoch 1/40\n",
            "124/124 [==============================] - 82s 479ms/step - loss: 3.4883 - accuracy: 0.0362 - val_loss: 3.4853 - val_accuracy: 0.0869\n",
            "Epoch 2/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 3.3358 - accuracy: 0.0718 - val_loss: 3.8364 - val_accuracy: 0.0202\n",
            "Epoch 3/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 3.0398 - accuracy: 0.1223 - val_loss: 3.1252 - val_accuracy: 0.0364\n",
            "Epoch 4/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 2.6309 - accuracy: 0.2128 - val_loss: 3.5153 - val_accuracy: 0.0894\n",
            "Epoch 5/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 2.2939 - accuracy: 0.3119 - val_loss: 3.7326 - val_accuracy: 0.0146\n",
            "Epoch 6/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 1.9911 - accuracy: 0.4091 - val_loss: 2.8820 - val_accuracy: 0.3449\n",
            "Epoch 7/40\n",
            "124/124 [==============================] - 46s 374ms/step - loss: 1.7474 - accuracy: 0.4918 - val_loss: 2.9364 - val_accuracy: 0.3419\n",
            "Epoch 8/40\n",
            "124/124 [==============================] - 46s 373ms/step - loss: 1.5644 - accuracy: 0.5520 - val_loss: 1.7746 - val_accuracy: 0.4692\n",
            "Epoch 9/40\n",
            "124/124 [==============================] - 46s 373ms/step - loss: 1.4186 - accuracy: 0.5955 - val_loss: 1.3983 - val_accuracy: 0.5879\n",
            "Epoch 10/40\n",
            "124/124 [==============================] - 45s 367ms/step - loss: 1.3021 - accuracy: 0.6261 - val_loss: 1.6262 - val_accuracy: 0.5227\n",
            "Epoch 11/40\n",
            "124/124 [==============================] - 46s 370ms/step - loss: 1.2284 - accuracy: 0.6457 - val_loss: 1.1566 - val_accuracy: 0.6556\n",
            "Epoch 12/40\n",
            "124/124 [==============================] - 46s 368ms/step - loss: 1.1394 - accuracy: 0.6682 - val_loss: 1.6968 - val_accuracy: 0.5242\n",
            "Epoch 13/40\n",
            "124/124 [==============================] - 46s 370ms/step - loss: 1.0548 - accuracy: 0.6845 - val_loss: 1.2849 - val_accuracy: 0.6328\n",
            "Epoch 14/40\n",
            "124/124 [==============================] - 46s 374ms/step - loss: 1.0145 - accuracy: 0.6985 - val_loss: 0.9505 - val_accuracy: 0.7101\n",
            "Epoch 15/40\n",
            "124/124 [==============================] - 46s 373ms/step - loss: 0.9317 - accuracy: 0.7182 - val_loss: 1.2408 - val_accuracy: 0.6561\n",
            "Epoch 16/40\n",
            "124/124 [==============================] - 45s 367ms/step - loss: 0.8482 - accuracy: 0.7455 - val_loss: 1.3946 - val_accuracy: 0.6086\n",
            "Epoch 17/40\n",
            "124/124 [==============================] - 46s 371ms/step - loss: 0.7839 - accuracy: 0.7556 - val_loss: 1.0741 - val_accuracy: 0.7025\n",
            "Epoch 18/40\n",
            "124/124 [==============================] - 46s 368ms/step - loss: 0.7051 - accuracy: 0.7852 - val_loss: 0.8828 - val_accuracy: 0.7232\n",
            "Epoch 19/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 0.6425 - accuracy: 0.8006 - val_loss: 0.9988 - val_accuracy: 0.7162\n",
            "Epoch 20/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 0.5978 - accuracy: 0.8100 - val_loss: 2.0365 - val_accuracy: 0.5167\n",
            "Epoch 21/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 0.5248 - accuracy: 0.8360 - val_loss: 0.6902 - val_accuracy: 0.8121\n",
            "Epoch 22/40\n",
            "124/124 [==============================] - 46s 374ms/step - loss: 0.4827 - accuracy: 0.8475 - val_loss: 1.1638 - val_accuracy: 0.7242\n",
            "Epoch 23/40\n",
            "124/124 [==============================] - 45s 367ms/step - loss: 0.4366 - accuracy: 0.8631 - val_loss: 1.3972 - val_accuracy: 0.6909\n",
            "Epoch 24/40\n",
            "124/124 [==============================] - 46s 370ms/step - loss: 0.4094 - accuracy: 0.8659 - val_loss: 2.4568 - val_accuracy: 0.6025\n",
            "Epoch 25/40\n",
            "124/124 [==============================] - 46s 368ms/step - loss: 0.3710 - accuracy: 0.8843 - val_loss: 0.5656 - val_accuracy: 0.8439\n",
            "Epoch 26/40\n",
            "124/124 [==============================] - 46s 375ms/step - loss: 0.3230 - accuracy: 0.8981 - val_loss: 0.8435 - val_accuracy: 0.8217\n",
            "Epoch 27/40\n",
            "124/124 [==============================] - 46s 373ms/step - loss: 0.3045 - accuracy: 0.9061 - val_loss: 0.8585 - val_accuracy: 0.8000\n",
            "Epoch 28/40\n",
            "124/124 [==============================] - 45s 367ms/step - loss: 0.2704 - accuracy: 0.9148 - val_loss: 0.6411 - val_accuracy: 0.8455\n",
            "Epoch 29/40\n",
            "124/124 [==============================] - 46s 374ms/step - loss: 0.2403 - accuracy: 0.9205 - val_loss: 0.7050 - val_accuracy: 0.8505\n",
            "Epoch 30/40\n",
            "124/124 [==============================] - 46s 371ms/step - loss: 0.2132 - accuracy: 0.9318 - val_loss: 0.5621 - val_accuracy: 0.8848\n",
            "Epoch 31/40\n",
            "124/124 [==============================] - 46s 368ms/step - loss: 0.2097 - accuracy: 0.9330 - val_loss: 0.4723 - val_accuracy: 0.8985\n",
            "Epoch 32/40\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 0.1785 - accuracy: 0.9429 - val_loss: 0.3080 - val_accuracy: 0.9354\n",
            "Epoch 33/40\n",
            "124/124 [==============================] - 46s 368ms/step - loss: 0.1694 - accuracy: 0.9461 - val_loss: 0.4648 - val_accuracy: 0.8838\n",
            "Epoch 34/40\n",
            "124/124 [==============================] - 46s 368ms/step - loss: 0.1604 - accuracy: 0.9486 - val_loss: 0.8783 - val_accuracy: 0.8116\n",
            "Epoch 35/40\n",
            "124/124 [==============================] - 46s 375ms/step - loss: 0.1344 - accuracy: 0.9569 - val_loss: 0.3652 - val_accuracy: 0.9323\n",
            "Epoch 36/40\n",
            "  4/124 [..............................] - ETA: 38s - loss: 0.1255 - accuracy: 0.9492"
          ]
        }
      ],
      "source": [
        "data_dir = '/content/drive/MyDrive/boongboong' # (본인 자동차 이미지 폴더 경로)\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory( data_dir, validation_split=0.2, subset='training', labels='inferred',\n",
        "                                                               label_mode='categorical', image_size=[224, 224], seed=123, interpolation='nearest', batch_size=64, shuffle=True )\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory( data_dir, validation_split=0.2, subset='validation', labels='inferred',\n",
        "                                                             label_mode='categorical', image_size=[224, 224], seed=123, interpolation='nearest', batch_size=64, shuffle=False )\n",
        "\n",
        "def convert_to_float(image, label):\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  return image, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE \n",
        "train_ds = (train_ds.map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)) \n",
        "val_ds = (val_ds.map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE))\n",
        "\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "num = 1\n",
        "for layer in base_model.layers:\n",
        "    if num >= 144:\n",
        "      layer.trainable = True\n",
        "    else:\n",
        "      layer.trainable = False\n",
        "    num += 1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(224,224,3)))\n",
        "\n",
        "model.add(base_model)\n",
        "\n",
        "model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(padding='same'))\n",
        "\n",
        "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(33 , activation = 'softmax'))\n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds,batch_size=64,epochs=40,validation_data=val_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_ds), model.evaluate(val_ds)"
      ],
      "metadata": {
        "id": "mozEutKjW1bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir2 = '/content/drive/MyDrive/cars/cars' # (본인 자동차 이미지 폴더 경로)\n",
        "\n",
        "train_ds2 = tf.keras.preprocessing.image_dataset_from_directory( data_dir2, validation_split=0.2, subset='training', labels='inferred',\n",
        "                                                               label_mode='categorical', image_size=[224, 224], seed=123, interpolation='nearest', batch_size=64, shuffle=True )\n",
        "\n",
        "val_ds2 = tf.keras.preprocessing.image_dataset_from_directory( data_dir2, validation_split=0.2, subset='validation', labels='inferred',\n",
        "                                                             label_mode='categorical', image_size=[224, 224], seed=123, interpolation='nearest', batch_size=64, shuffle=False )\n",
        "\n",
        "def convert_to_float(image, label):\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  return image, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE \n",
        "train_ds2 = (train_ds2.map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)) \n",
        "val_ds2 = (val_ds2.map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE))"
      ],
      "metadata": {
        "id": "_eYgQvvyRHpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "PrHtjyUesM5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = model.get_layer('dense_1')\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024,activation='relu')(x)\n",
        "x = layers.Dense(512,activation='relu')(x)\n",
        "x = layers.Dense(256,activation='relu')(x)\n",
        "x = layers.Dense(128,activation='relu')(x)\n",
        "x = layers.Dense(20,activation='softmax')(x)\n",
        "\n",
        "new_model = Model(model.input, x)"
      ],
      "metadata": {
        "id": "OVQ_BfAno4gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in new_model.layers:\n",
        "  layer.trainable = True"
      ],
      "metadata": {
        "id": "PWD6RaltQ5zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.compile(loss=tf.keras.losses.categorical_crossentropy, \n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5catKlfrQ7GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_history = new_model.fit(train_ds2,batch_size=64,epochs=40,validation_data=val_ds2)"
      ],
      "metadata": {
        "id": "AaxjPiByQ9Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.evaluate(train_ds2), new_model.evaluate(val_ds2)"
      ],
      "metadata": {
        "id": "ccAHtjxma9XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -qq \"/content/drive/MyDrive/test_data.zip\" -d \"/content/drive/MyDrive/test_data\""
      ],
      "metadata": {
        "id": "Nja3jrzAN_Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "plt.style.use('fivethirtyeight')\n",
        "fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
        "axes[0].plot(new_history.history[\"loss\"], 'r', label='Training loss')\n",
        "axes[0].plot(new_history.history[\"val_loss\"],'g',label='Validation loss' )\n",
        "axes[0].set_title('Kaggle Car Classification Training and Validation Loss')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "plt.ylim(-0.05,1.0)\n",
        "axes[1].plot (new_history.history[\"accuracy\"],'r',label= 'Training Accuracy')\n",
        "axes[1].plot (new_history.history[\"val_accuracy\"],'g',label= 'Validation Accuracy')\n",
        "axes[1].set_title('Kaggle Car Classification Training and Validation Accuracy')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        " \n",
        "plt.savefig(\"/content/drive/MyDrive/Kaggle Car Classification.jpg\")"
      ],
      "metadata": {
        "id": "OPLjdYFqbyJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix & classification report \n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "\n",
        "# in order to proceed following steps train_ds, val_ds dataset and  class_names should be set up \n",
        "\n",
        "#1. load model \n",
        "# model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/Base_CNN_model.keras\")\n",
        "\n",
        "\n",
        "#2. test data load  \n",
        "#!unzip -qq \"/content/drive/MyDrive/Colab Notebooks/test.zip\" -d \"/content/drive/MyDrive/Colab Notebooks/test\"\n",
        "data_dir2 = '/content/drive/MyDrive/test_data'\n",
        "\n",
        "#3. test dataset\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory( data_dir2, batch_size=64,\n",
        "                                                               labels='inferred',\n",
        "                                                               label_mode='categorical',\n",
        "                                                               image_size=[224, 224],\n",
        "                                                               interpolation='nearest')\n",
        "\n",
        "#4. prediction based on trained model  \n",
        "predict = model.predict(test_ds)\n",
        "\n",
        "#5. split test dataset\n",
        "(x,y),(xx,yy) = test_ds\n",
        "\n",
        "\n",
        "#6. reshape y data\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior(y)\n",
        "np_config.enable_numpy_behavior(yy)\n",
        "y1 = y.tolist()\n",
        "y2 = yy.tolist()\n",
        "y3 = y1+y2\n",
        "y4 = np.array(y3).reshape(99,-1)\n",
        "\n",
        "# check shpae of y4 and predict \n",
        "y4.shape, predict.shape\n",
        "\n",
        "#7. \n",
        "predict=np.argmax(predict, axis=1)\n",
        "y4=np.argmax(y4, axis=1)\n",
        "cm = confusion_matrix(y4, predict)\n",
        "print(cm)\n",
        "\n",
        "#8. precision, recall, f1 score \n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "p = precision_score(y4, predict, pos_label='positive', average='micro')\n",
        "print(p)\n",
        "r = recall_score(y4, predict, pos_label='positive', average='micro')\n",
        "print(r)\n",
        "f1 = f1_score(y4, predict, pos_label='positive', average='micro')\n",
        "print(f1)\n",
        "\n",
        "clas_names = test_ds.class_names\n",
        "#9. classification report \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y4, predict, target_names=class_names))\n",
        "\n",
        "#10. confusion matrix visualization\n",
        "class_count = len(class_names)\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
        "plt.xticks(np.arange(class_count)+.5, class_names, rotation= 90)\n",
        "plt.yticks(np.arange(class_count)+.5, class_names, rotation=0)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Base CNN Model Confusion Matrix\")\n",
        "plt.savefig('/content/drive/MyDrive/Colab Notebooks/baseCNN_model_confusion_matrix.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7FTZU_5FOOif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "confusion_matrix = metrics.confusion_matrix( )\n",
        "print(confusion_matrix)"
      ],
      "metadata": {
        "id": "Rg49Gbn8dweo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('machine')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ba36d0bac3973a45270dac29dd7867478d264cacedda49a3de9c10c6ae4d60ef"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}