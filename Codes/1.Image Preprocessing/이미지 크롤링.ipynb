{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11562c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib import request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Selenium 을 이용한 이미지 크롤링\n",
    "from selenium import webdriver\n",
    "from urllib.request import urlopen\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6340161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 키워드 리스트\n",
    "model_1 = [\n",
    "       'XM3 E-TECH 하이브리드', 'XM3', 'QM6', 'SM6', '르노 MASTER'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9312ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수로 만들어서 나머지 모델 이미지 크롤링\n",
    "def model_img_crawling(model):\n",
    "# 1. 이미지 저장할 상위 폴더 생성\n",
    "    if not os.path.isdir(f\"{model}/\"):\n",
    "       os.makedirs(f\"{model}/\")\n",
    "\n",
    "# 2. 크롬 웹드라이버 연결\n",
    "    driver = webdriver.Chrome('C:/Users/Gunhee/Downloads/chromedriver_win32/chromedriver.exe')\n",
    "    driver.get(\"https://www.google.co.kr/imghp?hl=ko\")\n",
    "\n",
    "\n",
    "# 3. 검색어 입력하기\n",
    "    search = model\n",
    "    elem = driver.find_element(By.NAME, \"q\")\n",
    "    elem.send_keys(search)\n",
    "    elem.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "# 4. 스크롤 끝까지 내리기\n",
    "    SCROLL_PAUSE_TIME = 1\n",
    "\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if new_height == last_height:\n",
    "            try:\n",
    "                driver.find_element(By.CSS_SELECTOR, \".mye4qd\").click()\n",
    "            except:\n",
    "                break\n",
    "        last_height = new_height\n",
    "\n",
    "\n",
    "\n",
    "# 5. 이미지 찾아서 원본 파일로 저장하기\n",
    "    images = driver.find_elements(By.CSS_SELECTOR, \".rg_i.Q4LuWd\")\n",
    "    count = 0\n",
    "\n",
    "    for image in images:\n",
    "        try:\n",
    "            image.click()\n",
    "            time.sleep(2)\n",
    "            image = image.get_attribute('src')\n",
    "            urllib.request.urlretrieve(image, f\"{model}/\" + search + \"_\" + str(count) + \".jpg\")\n",
    "            print(f\"Image saved: {model}_{count}.jpg\")\n",
    "            count += 1\n",
    "            if count > 200:\n",
    "#                 raise Exception(f'{count}개 이미지를 다운로드 하였습니다.')\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 함수 실행\n",
    "for i in model_1:\n",
    "    model_img_crawling(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699557c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad826a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 이미지를 넘파이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4dbbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import time\n",
    "\n",
    "import urllib\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb380b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 url을 np.array로 바꿔주는 함수\n",
    "def url_to_image(url, readFlag=cv2.IMREAD_COLOR):  \n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    gcontext = ssl.SSLContext()\n",
    "    webpage = urlopen(req,context=gcontext,timeout=10)  # 정상적으로 열리지 않는 url이 있어서 timeout 옵션 부여\n",
    "    image = np.asarray(bytearray(webpage.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a65899",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = {}\n",
    "carname =['GV80','G90','G70','K5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(carname):  # 크롤링하여 dictionary 형태로 저장하는 함수\n",
    "    car[carname] = []\n",
    "    \n",
    "    while(True):\n",
    "        try:\n",
    "            driver = webdriver.Chrome('chromedriver')  # 1. 구글 이미지 접속\n",
    "            url = 'https://www.google.com/imghp'\n",
    "            driver.get(url)\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    browser = driver.find_element(By.NAME,\"q\")  # 2. carname을 매개변수로 받아서 검색\n",
    "    browser.send_keys(carname)\n",
    "    browser.send_keys('\\n')\n",
    "    driver.implicitly_wait(3)\n",
    "    \n",
    "    selenium_scroll(driver)  # 3. 스크롤 끝까지 내리기\n",
    "       \n",
    "    time.sleep(3)\n",
    "    \n",
    "    html = driver.page_source  # 4. 스크롤 끝까지 내린 상태에서 페이지 소스 변수로 저장\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    imgs = driver.find_elements(By.CSS_SELECTOR, '#islrg > div.islrc > div a.wXeWr.islib.nfEiy')\n",
    "       \n",
    "    for i in range(len(imgs)):\n",
    "        if i >= 500:  # 최대 500장의 이미지 저장\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            imgs[i].click()  # 5. 이미지 클릭\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        count = 0\n",
    "        while(True):\n",
    "            if count > 10:\n",
    "                break\n",
    "            count += 1\n",
    "            try:\n",
    "                # 6. 클릭한 이미지에서 url 정보 가져오기\n",
    "                image = driver.find_element(By.CSS_SELECTOR, '#Sva75c > div > div > div.pxAole > div.tvh9oe.BIB1wf > c-wiz > div > div.OUZ5W > div.zjoqD > div.qdnLaf.isv-id > div > a')\n",
    "                time.sleep(0.5)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        count2 = 0\n",
    "        while(True):\n",
    "            if count2 > 5:\n",
    "                break\n",
    "            count2 += 1\n",
    "            try:\n",
    "                # 7. 가져온 url을 통해 이미지를 np.array로 저장 후 dictionary 안의 리스트에 저장\n",
    "                image = image.find_element(By.TAG_NAME, 'img').get_attribute('src')\n",
    "                image = url_to_image(image)\n",
    "                car[carname].append(image)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55495f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawling(carname[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('car project/car.npy', car)  # dictionary 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06056ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = np.load(('car project/car.npy'),allow_pickle='TRUE').item()  # 저장한 .npy 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car.keys()  # 정상적으로 불러왔는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf91b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e152776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d534a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
